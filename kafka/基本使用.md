##### 优点

1. 解耦
2. 可恢复
3. 缓冲
4. 灵活性
5. 峰值处理
6. 异步通信

##### 发布订阅模式

发布订阅模式将消息发布到tpic，同时有多个消费者消费该数据，消费者消费数据之后不会清除消息，将会被所有的订阅者消费，也就是说fvp的状态码可以被好多个系统同时收到

1. 消费者主动拉

   消费者的消费速度由消费者自己决定，但是基于拉取的模式也有自己的缺点，需要消费者维护一个轮询进程去时刻关注中间件里面到底有没有数据，造成资源浪费

2. 中间件自己推

   发布订阅的模式的消费速度是由中间件决定，而不是客户端决定

##### kafka名词解释

1. 消费者

2. Broker

   kafka集群中的一个节点，别被这个单词误导了，他就是一个服务节点，在设置一个Topic的时候，可以指定它有几个partition，也就是把数据分到几个节点上去

3. Topic

   数据分类，kafka集群节点中的一个数据类型，可以理解为表名

4. Partition 

   一个Topic分区，可以理解为某个节点上实际的表

5. 然后就涉及到Leader的概念了

   kafka的集群的同时，虽然数据放在多个节点上，节点虽然是分片，但同时也担任了另一个节点的容错节点，

6. kafka怪异的分区策略

   在这种情况下，如果要获取某个topic的数据，应该是获取集群中所有节点上该topic所有Leader分区的数据，因为在一些节点上可能根本没有这个分区的存在

7. 消费组

   某一个分区只能被一个消费组中的某一个消费者所消费

   比如全货机航班任务，只能被datainterface的一台机器消费，但是可以同时被航空和ghs消费

8. zookeeper

   监控某一个消费组消费某一个Topic的偏移量,注意：0.9版本后offset将保存在kafka自定义的区域中，默认七天

##### 图解

![无标题](C:\Users\皿煮国的潜逃败类\Desktop\无标题.png)

##### 安装

> 记住kafka的日志文件中，log还有数据的意思，不止是指日志

```
tar -zxvf 安装包
mkdir /usr/local/kakfa/logs
# 生产者配置信息 server.properties
# 集群中的唯一id 必须是一个整数并且唯一标志
broker.id = 0
# kafka数据的存储位置，记住不是日志地址
log.dirs = /usr/local/kafka/data
# 数据的保存时间
log.retention.hours = 168 
# 数据的保存大小
log.segment.bytes = 1073741824 
# zookeeper的地址
zookeeper.connection = localhost:2181

# 消费者配置信息 consumer.properties
```

##### 基本使用

```
# 启动kafka
bin/kafka-server-start.sh config/server.properties

# 创建主题
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 
--partitions 1 --topic topic-name

# 生产者提供数据
./bin/kafka-console-producer.sh --broker-list 192.168.43.130:9092 --topic test2


# 客户端获取数据 获取全部
./bin/kafka-console-consumer.sh --zookeeper 192.168.43.130:2181 -topic test3 --from-beginning

# 获取消费者重启后，生产者生成的数据
./bin/kafka-console-consumer.sh --bootstrap-server 192.168.43.130:9092 --topic test1

```

1.每一台使用启动的kafka都会在zk上保存一份节点数据,如broker.id = 0的数据格式如下

```json
# /brokers/ids/0
{
    "listener_security_protocol_map":{
        "PLAINTEXT":"PLAINTEXT"
    },
     # 节点地址端口信息
    "endpoints":[
        "PLAINTEXT://192.168.43.130:9092"
    ],
    "jmx_port":-1,
    "host":"192.168.43.130",
    "timestamp":"1595080868091",
    "port":9092,
    "version":4
}
```

2.每一个主题的分区也在zk上保留了一份数据

```json
# /brokers/ids/topics/topic_name/partitions/0/state
{
    # 表示kafka集群中的中央控制器选举次数
    "controller_epoch":6,
    # 该分区当前的leader节点
    "leader":1,
    "version":1,
    # 该分区 leader选举次数
    "leader_epoch":3,
    # 同步副本组brokerId列表,如果开启了集群模式
    "isr":[
        1,0,2
    ]
}
```

3.概念

- 启动kafka时会向zk写入节点信息

- 创建主题时会向zk写入主题和分区的信息

- 写入数据和获取数据时，会先请求zk获取到leader地址，所以必须保证集群中leader的正常连接

- 使用如果多台一起挂掉，将会出现没有选择leader的情况，那么再次开机一定至少要把最后一台打开

- 容错：当一台leader挂掉的时候，kafka集群会从isr数组中找到另外一个节点设置为分区leader

  如果连续挂掉--replication-factor数量，也就是全部挂掉了，该topic将不再可用

  

#####  使用kafkaTools进行图形化界面管理

```bash
# kafkatool.vmoptions
-Xmx4096m
-Xmx4096m
# 注意：kafka中数据量过大时，需要更大的内存来进行数据展示
```

##### Topic增删改查

```bash
# 增
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 
--partitions 1 --topic topic-name

# 删
bin/kafka-topics.sh --delete --zookeeper 192.168.43.130 --topic topic_name
# 此处有一个坑，如果不设置delete.topic.enable那么删除只是zk的节点数据，kafka内的数据并不会被删

# 查 查询分区信息，可以管康到分区的leader,分区的备份数
bin/kafka-topics.sh --describe --topic topic_name --zokeeper 192.168.43.130:2181
# print:
Topic:test4	PartitionCount:1	ReplicationFactor:2	Configs:
Topic:test4	Partition: 0	Leader: 0	Replicas: 0,1	Isr: 1,0

# 注意：kafka设置分区数可以大于节点数，但是一个分区的备份数不能大于节点数
```



##### offsets的概念

> _consumer_offsets 默认为50个

```bash
bin/kafka-console-consumer.sh --topic first --bootstrap-server 192.168.43.130:2181


# 删除zk全部数据zkData下面的version-2文件夹直接干掉
```



##### kafka数据文件

- 00000000000000000.log 分区文件

  当超过一定大小就会重新创建

- 00000000000000000.index 

  对于分区文件的定位作用

  ```
  # 索引文件的内容
  消息id 偏移量 文件大小
  # 根据消息id获得磁盘中偏移量也就是起点位置，然后通过文件大小得到终点位置
  ```

- 00000000000000000.timeindex

##### 分区原则

1. 指定partition的情况下，使用指明的值作为partition值
2. 没有指明partition值但是有key的情况下，将key的hash值与topic的partition数取余
3. 既没有partition数又没有key的情况下，第一次随机调用取一个随机数，然后每次递增并对此数取余，也就是轮询

##### 数据可靠性

- 生成者确认集群全部接收到消息ack

  | 方案                        | 优点                                         | 缺点                                                         |
  | --------------------------- | -------------------------------------------- | ------------------------------------------------------------ |
  | 半数以上完成同步，就发送ack | 延迟低                                       | 选举新leader时，容忍n台机器故障需要2n+1个副本 , 假设刚好只同步了一半以上的节点也就是n+1，那么刚好挂掉的n台又都是有数据的，那么为了至少剩下一台，必须要2n+1个副本 |
  | 全部完成同步，才发送ack     | 选举新leader时，容忍n台机器故障需要n+1个副本 | 延迟高                                                       |

  **kafka选择了第二种方案，没有选择2n+1这种资源消耗较大的方案，但是如果在同步的时候出现一台机器挂了，那么永远收不到ack，这就引入了ISR的概念**

- **ISR**

  leader维护了一个动态的in-sync replica set 意思是和leader保持同步的follower的集合，当ISR中的follower完成数据同步后，leader就会给follower和proceduer发送ack,**如果follower长时间没有向leader同步数据，该follower将被踢出ISR**,该事件阈值由replica.lag.time.max.ms参数设置

  **在老版本的条件中，要加入ISR，必须在规定事件内同步数据，并且和leader的条数差距在一定范围内**

  新版本后，干掉了条数的约定

  **leader发生故障后，就会从ISR中重新选举新的leader**

  

  ##### 应答机制ACK参数配置

  0:producer 不等待broker的ack，这一操作提供了最低延迟，延时最低，最容易丢数据

  1:producer只等待leader写完，如果leader写完就挂了，follower还没有接收完数据，那么也会丢数据

  -1:producer等待所有节点数据写完，但是如果在follower同步完成后，发送ack前，leader发生故障，将会造成数据重复

  

  ##### 数据一致性

  如果follower没有同步完，leader挂掉了，然后又连上来了，那么将会造成不同leader节点，不同数据的情况

  这就涉及到了**高水位概念HW**

  对于消费者来说，一个集群中的follower的数据，只能看到高水位之前的数据，也就是每一个leader都将建立一个水位，**当一个未完成同步的follower成为leader时，将会用当前leader的数据offset的作为水位，水位之后不可见**，这就保证了切换leader后消费者数据一致性

  问题：如果原来的leader回来了，现在leader水位之后的数据咋办

  直接干掉，虽然这样数据会丢失或重复，但是保证了数据一致性

  

  #####  Exactly Once

  AtLeastOnce + 幂等性 =  Exactly Once

  enable.idompotence  = true

  幂等性无法保证跨分区跨会话的重复性

  

  ##### 消费者

  - 分区分配策略

    - RoundRobin

      如果一个消费组订阅了两个topic，那么将会把两个分区当作一个topic来看待，然后轮询到消费组中每个机器,必须保证两个topic中的内容一样的

    - Range(默认)

      每个topic单独进行考虑，但是当topic中partition/consumer不对等的时候，会出现消费组中某个节点过量消费的情况

  ##### offset

  consumer消费的过程可能出现宕机故障，连起来后重新消费的情况下,如何在之前的位置接着消费

  ```
  offset = 消费组名 + topic + partition 
  
  # 如果时控制台命令，需要先更改了consumer的group配置，否则每一次都会重新启动一个消费组，那么关闭重新开启就会消费不到之前的数据
  
  ```

  ##### 事务

  事务可以保证kafka在exactly once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败

  

  

  

  

  

  

  

  

  

  

  

  



























